# ReMuQ: End-to-end Knowledge Retrieval with Multi-modal Queries

This repo provides the resource of [our paper](https://arxiv.org/abs/2306.00424) which aims to 1) introduce a new benchmark for multimodal-query retrieval task; 2) build an end-to-end multimodal retriever along with multimodal pretraining task. Check out our paper for more details. 

## Resource 

### ReMuQ: 
A dataset for multimodal-query retriever. We turned [WebQA](https://arxiv.org/abs/2109.00590) into a multimodal query retrieval task by augmenting the WebQA questions and adding images to the questions as new multimodal-queries along with a large text-based courpus.  

you can download the data from [this Link](https://drive.google.com/drive/folders/1UCnhxJ3LwXLGSqFOOso4ifHLVjGKaR96?usp=sharing).

### How to read the image?

We save the image into tsv format for efficient storage purpose. See read_tsv_img.ipynb notebook how to open an image. 

